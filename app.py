# app.py
import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
from collections import Counter, defaultdict
import re
import random
import math
import datetime

# -------------------------------
# KULLANIM / Ã‡ALIÅTIRMA
# -------------------------------
# 1) Google Cloud Console -> YouTube Data API v3 aktif et -> API key al
# 2) Bu dosyada API_KEY deÄŸiÅŸkenine anahtarÄ± koy
# 3) Gerekli paketleri yÃ¼kle:
#    pip install streamlit pandas google-api-python-client
# 4) Ã‡alÄ±ÅŸtÄ±r:
#    streamlit run app.py
#
# UYARI: YouTube Data API kota sÄ±nÄ±rlarÄ±nÄ±z olabilir. Ã‡ok sÄ±k istek atmayÄ±n.

# -------------------------------
# AYARLAR
# -------------------------------
API_KEY = "BURAYA_YOUR_YOUTUBE_API_KEY_YAZIN"  # <<-- buraya YouTube API key
API_SERVICE_NAME = "youtube"
API_VERSION = "v3"

# Basit stopword set (TR + EN); ihtiyaÃ§ varsa geniÅŸletin
STOPWORDS_TR = {
    "ve","ile","bir","bu","da","de","iÃ§in","ben","sen","o","gibi","Ã§ok","en","ama",
    "ise","olarak","kadar","mi","mÄ±","mu","mÃ¼","var","yok","ÅŸu","burada","hemen",
    "ile", "nasÄ±l", "niÃ§in", "neden"
}
STOPWORDS_EN = {
    "the","and","for","with","this","that","from","your","you","are","how","what",
    "will","can","have","has","but","not","our","they","their","about","more","get",
    "a","an","in","on","to","of","is","it"
}
STOPWORDS = STOPWORDS_TR.union(STOPWORDS_EN)

# Power words & hooks to increase CTR
POWER_WORDS = [
    "HÄ±zlÄ±", "Kolay", "Kesin", "AdÄ±m AdÄ±m", "Uzman", "GÃ¼ncel",
    "2025", "SÄ±fÄ±rdan", "BaÅŸlangÄ±Ã§", "Etkili", "SÄ±rlarÄ±", "Ä°puÃ§larÄ±",
    "Taktikler", "Hatalar", "En Ä°yi", "Mutlaka"
]
BRACKET_OPTIONS = ["(Kolay)", "(2025)", "[HÄ±zlÄ± Rehber]", "(%100 Ã‡alÄ±ÅŸÄ±r)"]

# Utility: YouTube client
def get_youtube_client():
    if not API_KEY or API_KEY.strip() == "":
        return None
    try:
        return build(API_SERVICE_NAME, API_VERSION, developerKey=API_KEY)
    except Exception as e:
        st.error(f"YouTube client baÅŸlatÄ±lamadÄ±: {e}")
        return None

# -------------------------------
# TEXT PROCESSING & SEO ALGORITHMASI
# -------------------------------
def clean_text(text):
    if not text:
        return ""
    # remove urls and extra spaces
    text = re.sub(r'http\S+', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def tokenize(text):
    text = clean_text(text).lower()
    tokens = re.findall(r"[a-zA-ZÄ±ÄŸÃ¼ÅŸÃ¶Ã§Ä°ÄÃœÅÃ–Ã‡0-9]+", text)
    tokens = [t for t in tokens if t not in STOPWORDS and len(t) > 2]
    return tokens

def extract_ngrams(tokens, n):
    if len(tokens) < n:
        return []
    return [" ".join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]

def score_keywords(titles, descriptions):
    """
    Basit TF scoring with title-weight boost.
    Returns sorted keywords (unigrams + bigrams) with scores.
    """
    tf = Counter()
    # Title words weighted higher
    for t in titles:
        toks = tokenize(t)
        for tok in toks:
            tf[tok] += 3  # title weight
        # bigrams from title
        for bg in extract_ngrams(toks, 2):
            tf[bg] += 4
    # Description words less weight
    for d in descriptions:
        toks = tokenize(d)
        for tok in toks:
            tf[tok] += 1
        for bg in extract_ngrams(toks, 2):
            tf[bg] += 1.5

    # Normalize / sort
    items = sorted(tf.items(), key=lambda x: x[1], reverse=True)
    return items

def pick_primary_keyword(topic, scored_keywords):
    # Prefer exact topic tokens if present; else top keyword
    topic_tokens = tokenize(topic)
    for k, _ in scored_keywords:
        # full match
        if k in topic_tokens or all(tok in k.split() for tok in topic_tokens if len(tok)>2):
            return k
    return scored_keywords[0][0] if scored_keywords else topic

def make_title(primary, secondary_candidates, topic):
    """
    Title heuristics:
     - include primary keyword prominently
     - include a hook/power word or number + bracket
     - length <= 100
    """
    # try variants
    variants = []
    # Variant: "Primary â€” Hook"
    hook = random.choice(POWER_WORDS)
    variants.append(f"{primary.title()} â€” {hook}")
    # Variant: "How to Primary (2025) | Quick Guide"
    variants.append(f"{primary.title()} {random.choice(BRACKET_OPTIONS)} | HÄ±zlÄ± Rehber")
    # Variant: "Top N Primary Tips"
    n = random.choice([5,7,10])
    variants.append(f"{n} {primary.title()} Ä°pucu | {random.choice(['BaÅŸlangÄ±Ã§','HÄ±zlÄ± Ã–ÄŸrenme'])}")
    # Variant: "Primary: Secondary â€” Hook"
    if secondary_candidates:
        sec = secondary_candidates[0].title()
        variants.append(f"{primary.title()}: {sec} â€” {random.choice(POWER_WORDS)}")
    # Variant: topic-based fallback
    variants.append(f"{topic.title()} â€” {random.choice(POWER_WORDS)}")
    # Choose best -> prefer medium length and containing primary
    def score_variant(v):
        length_penalty = abs(len(v) - 60) / 60  # prefer around 60 chars
        power_bonus = sum(1 for p in POWER_WORDS if p in v)
        return power_bonus - length_penalty
    variants = sorted(variants, key=score_variant, reverse=True)
    title = variants[0][:100]
    # ensure primary appears
    if primary.lower() not in title.lower():
        title = f"{primary.title()} â€” {title}"
    return title

def make_description(topic, primary_keyword, top_keywords):
    # First 1-2 lines: hook + primary keyword; these must appear early (first 100 chars)
    hook_templates = [
        f"Bu videoda {primary_keyword} hakkÄ±nda bilmeniz gereken her ÅŸeyi adÄ±m adÄ±m Ã¶ÄŸreneceksiniz.",
        f"{primary_keyword} konusunda hÄ±zlÄ± ve etkili bir rehber: baÅŸlangÄ±Ã§tan ileri seviyeye.",
        f"{primary_keyword} â€” en gÃ¼ncel yÃ¶ntemler ve uygulamalÄ± Ã¶rneklerle."
    ]
    first_lines = random.choice(hook_templates)

    # build sections
    topics_sample = ", ".join(top_keywords[:8])
    body = (
        f"{first_lines}\n\n"
        f"Videoda ele alÄ±nan baÅŸlÄ±ca konular: {topics_sample}.\n\n"
        "ğŸ“Œ Bu videoda:\n"
        "- Temel kavramlar ve neden Ã¶nemli olduklarÄ±nÄ± anlattÄ±k\n"
        "- UygulamalÄ± Ã¶rneklerle nasÄ±l yapÄ±lacaÄŸÄ±nÄ± gÃ¶sterdik\n"
        "- SÄ±k yapÄ±lan hatalar ve nasÄ±l kaÃ§Ä±nÄ±lacaÄŸÄ±\n\n"
        "â± BÃ¶lÃ¼mler:\n"
        # placeholder chapters; user will edit times before upload
        "00:00 â€“ GiriÅŸ\n05:00 â€“ Temel Kavramlar\n12:00 â€“ UygulamalÄ± Ã–rnekler\n20:00 â€“ Ä°leri Ä°puÃ§larÄ±\n\n"
        "ğŸ‘‰ Videoyu beÄŸendiyseniz lÃ¼tfen beÄŸen butonuna basÄ±n ve abone olun. Yorumlarda hangi konuyu daha detaylÄ± gÃ¶rmek istediÄŸinizi yazÄ±n.\n\n"
    )
    # Add suggested hashtags at end (will be returned separately too)
    return first_lines + "\n\n" + body

def generate_tags(topic, scored_keywords, desired=40):
    """
    Build 40 tags mixing:
     - exact topic tokens
     - top unigrams
     - bigrams
     - english variations (simple heuristics)
     - suffixes and tag templates
    """
    tags = []
    topic_tokens = tokenize(topic)
    # 1. topic tokens
    for t in topic_tokens:
        if t not in tags: tags.append(t)
    # 2. top keywords (scored_keywords is list of tuples)
    for k, _ in scored_keywords:
        if k not in tags:
            tags.append(k)
    # 3. split bigrams into components
    for t in list(tags):
        for part in t.split():
            if part not in tags:
                tags.append(part)
    # 4. english simple map / suffixes
    suffixes = ["tutorial","howto","guide","tips","beginner","2025","easy","fast","tr"]
    for s in suffixes:
        candidate = f"{topic_tokens[0]} {s}" if topic_tokens else s
        candidate = candidate.strip()
        if candidate not in tags:
            tags.append(candidate)
    # 5. category-ish tags & variants
    cat = ["eÄŸitim","Ã¶ÄŸrenme","tutorial","ders","nasÄ±l yapÄ±lÄ±r"]
    for c in cat:
        if c not in tags:
            tags.append(c)
    # 6. ensure uniqueness & lowercase, trim/pad to desired
    final = []
    for t in tags:
        t_clean = t.lower()[:50]  # youtube tag length limit roughly 500 chars total; per tag up to 500? keep 50 safe
        if t_clean not in final:
            final.append(t_clean)
        if len(final) >= desired:
            break
    # pad if needed with numbered variants
    i = 1
    while len(final) < desired:
        cand = f"{topic.replace(' ', '_')}_{i}"
        final.append(cand[:50])
        i += 1
    return final[:desired]

def pick_hashtags(tags):
    # choose up to 3 hashtag candidates from top tags (no spaces)
    hashtags = []
    for t in tags:
        if len(hashtags) >= 3:
            break
        if " " not in t and len(t) > 2 and not any(ch.isdigit() for ch in t[:1]):
            hashtags.append("#" + t)
    # fallback generate from first tag words
    if not hashtags:
        hashtags = ["#" + tags[0].split()[0]]
    return hashtags

def suggest_thumbnail_text(primary, secondary):
    # Short punchy phrase
    opts = [
        f"EN Ä°YÄ° {primary.upper()}",
        f"{primary.upper()} HIZLI Ã–ÄREN",
        f"{secondary.upper() if secondary else 'KISA REHBER'}",
        f"{primary.upper()} - ADIM ADIM"
    ]
    return random.choice(opts)

# -------------------------------
# STREAMLIT UI
# -------------------------------
st.set_page_config(page_title="YouTube Upload Helper (SEO+Trend)", page_icon="ğŸ“º", layout="wide")
st.title("YouTube Upload Helper â€” Yeni BaÅŸlayanlar iÃ§in YÃ¼klemeye HazÄ±r Ã–neriler")

tab1, tab2, tab3 = st.tabs(["Trend Analizi", "Video YÃ¼kleme YardÄ±mcÄ±sÄ±", "YÃ¼kleme Kontrol Listesi & Ä°puÃ§larÄ±"])

# ---------- TAB 1: Trend Analizi ----------
with tab1:
    st.header("Trend Analizi â€” Ãœlke & Konu BazlÄ±")
    yt = get_youtube_client()
    if not yt:
        st.warning("YouTube API key eksik veya hatalÄ±. Ãœstte API_KEY deÄŸiÅŸkenine anahtarÄ±nÄ±zÄ± ekleyin.")
    query = st.text_input("Arama terimi (Ã¶r: Python makine Ã¶ÄŸrenmesi):", value="python tutorial")
    country_code = st.selectbox("Ãœlke (regionCode):", ["TR","US","GB","DE","FR","IN","JP","BR","CA","ES"], index=0)
    max_results = st.slider("Ã‡ekilecek video sayÄ±sÄ±", 5, 50, 15)

    if st.button("Trendleri Ã‡ek ve GÃ¶ster"):
        if not yt:
            st.stop()
        try:
            req = yt.search().list(
                q=query,
                part="snippet",
                type="video",
                order="viewCount",
                regionCode=country_code,
                maxResults=max_results
            )
            res = req.execute()
            videos = []
            for item in res.get("items", []):
                snp = item.get("snippet", {})
                videos.append({
                    "BaÅŸlÄ±k": snp.get("title"),
                    "Kanal": snp.get("channelTitle"),
                    "YayÄ±n Tarihi": snp.get("publishedAt"),
                    "AÃ§Ä±klama (Ã–nizleme)": (snp.get("description") or "")[:250],
                    "Link": f"https://www.youtube.com/watch?v={item['id']['videoId']}"
                })
            df = pd.DataFrame(videos)
            st.dataframe(df)
            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button("CSV Ä°ndir", csv, "youtube_trends.csv", "text/csv")
        except Exception as e:
            st.error(f"YouTube API hatasÄ±: {e}")

# ---------- TAB 2: Video YÃ¼kleme YardÄ±mcÄ±sÄ± ----------
with tab2:
    st.header("Video YÃ¼kleme YardÄ±mcÄ±sÄ± â€” YÃ¼klemeye HazÄ±r Ã‡Ä±ktÄ±lar")
    with st.form("upload_helper_form"):
        topic = st.text_input("Video konusu (kÄ±sa ve net):", value="Python ile Yapay Zeka")
        country2 = st.selectbox("Trend Analizini Hangi Ãœlke Ãœzerinden YapalÄ±m?", ["TR","US","GB","DE","FR","IN","JP","BR","CA","ES"], index=0)
        results_count = st.slider("Trend'den kaÃ§ video analiz edilsin?", 5, 50, 15)
        preferred_length = st.selectbox("Hedef BaÅŸlÄ±k UzunluÄŸu:", ["KÄ±sa (â‰¤50)", "Orta (~60)", "Uzun (â‰¤100)"], index=1)
        submit = st.form_submit_button("Analiz Et & Ã–neri OluÅŸtur")

    if submit:
        yt = get_youtube_client()
        if not yt:
            st.error("YouTube API client baÅŸlatÄ±lamadÄ±. API_KEY kontrol edin.")
            st.stop()
        if not topic.strip():
            st.warning("LÃ¼tfen bir video konusu girin.")
            st.stop()

        with st.spinner("Trend videolarÄ± Ã§ekiliyor, anahtar kelimeler analiz ediliyor..."):
            try:
                req = yt.search().list(
                    q=topic,
                    part="snippet",
                    type="video",
                    order="viewCount",
                    regionCode=country2,
                    maxResults=results_count
                )
                res = req.execute()
            except Exception as e:
                st.error(f"YouTube aramasÄ± baÅŸarÄ±sÄ±z: {e}")
                st.stop()

            titles = []
            descriptions = []
            for item in res.get("items", []):
                sn = item.get("snippet", {})
                titles.append(clean_text(sn.get("title", "")))
                descriptions.append(clean_text(sn.get("description", "")))

            # Score keywords
            scored = score_keywords(titles, descriptions)  # list of (kw, score)
            # Extract lists
            scored_keywords = [k for k, s in scored]
            # Separate unigrams and multiword
            unigrams = [k for k in scored_keywords if " " not in k]
            multi = [k for k in scored_keywords if " " in k]

            primary = pick_primary_keyword(topic, scored)
            secondary = multi[0] if multi else (unigrams[1] if len(unigrams)>1 else None)

            # Build title & description & tags
            suggested_title = make_title(primary, [secondary] if secondary else [], topic)
            suggested_description = make_description(topic, primary, scored_keywords)
            suggested_tags = generate_tags(topic, scored, desired=40)
            suggested_hashtags = pick_hashtags(suggested_tags)
            thumbnail_text = suggest_thumbnail_text(primary, secondary)

            # Show results with copy buttons
            st.subheader("ğŸ”– Ã–nerilen BaÅŸlÄ±k (kopyala & yapÄ±ÅŸtÄ±r hazÄ±r)")
            st.code(suggested_title, language="text")
            st.markdown("**Uzunluk:** " + str(len(suggested_title)) + " karakter")

            st.subheader("ğŸ“ Ã–nerilen AÃ§Ä±klama (ilk 2 satÄ±r Ã¶nemli; 100-200 karakter iÃ§ine CTA koyun)")
            st.text_area("AÃ§Ä±klama (dÃ¼zenleyip kopyalayÄ±n)", value=suggested_description, height=260)

            st.subheader(f"ğŸ·ï¸ Ã–nerilen 40 Etiket")
            st.write(", ".join(suggested_tags))

            st.subheader("ğŸ”— Ã–nerilen Hashtagler (aÃ§Ä±klama iÃ§inde kullan)")
            st.write(" ".join(suggested_hashtags))

            st.subheader("ğŸ–¼ Thumbnail Ã–nerisi")
            st.write(f"Metin Ã¶nerisi: **{thumbnail_text}**")
            st.write("TasarÄ±m Ã¶nerisi: bÃ¼yÃ¼k kontrastlÄ± yazÄ± (Ã¶r: beyaz/yellow), koyu arka plan, yÃ¼z/duygu ifadeleri, kÃ¼Ã§Ã¼k metin deÄŸil bÃ¼yÃ¼k ve okunur")

            # Offer to download JSON with everything
            output = {
                "title": suggested_title,
                "description": suggested_description,
                "tags": suggested_tags,
                "hashtags": suggested_hashtags,
                "thumbnail_text": thumbnail_text,
                "primary_keyword": primary,
                "secondary_keyword": secondary,
                "analysis_date": datetime.datetime.utcnow().isoformat() + "Z",
                "source_country": country2,
                "analyzed_count": results_count
            }
            st.download_button("ğŸ“¥ Ã–nerileri JSON olarak indir", data=pd.Series(output).to_json(), file_name="youtube_suggestion.json", mime="application/json")

            # Show top keywords summary
            st.markdown("**Analiz Ã–zeti â€” Ã–ne Ã‡Ä±kan Anahtar Kelimeler (Top 20)**")
            st.write(", ".join(scored_keywords[:20]))

# ---------- TAB 3: YÃœKLEME KONTROL LÄ°STESÄ° & Ä°PUÃ‡LAR ----------
with tab3:
    st.header("YÃ¼kleme Kontrol Listesi & Kanal BÃ¼yÃ¼tme Ä°puÃ§larÄ± (Yeni BaÅŸlayanlar iÃ§in)")
    st.markdown("""
    **YÃ¼kleme Kontrol Listesi (Upload-ready checklist):**
    1. BaÅŸlÄ±k: Ä°lk 60 karakter gÃ¼Ã§lÃ¼, iÃ§inde anahtar kelime olsun. Parantez / yÄ±l / sayÄ± kullan.
    2. AÃ§Ä±klama: Ä°lk 1-2 satÄ±r (100-150 karakter) izleyiciyi Ã§ekmeli â€” anahtar kelime + CTA (abone ol) olmalÄ±.
    3. Etiketler: 40 adet; anahtar kelime + long-tail varyasyonlar + Ä°ngilizce varyasyonlar.
    4. Hashtag: 1-3 hashtag aÃ§Ä±klamada (YouTube ilk 3'Ã¼ Ã¼stte gÃ¶sterir).
    5. Thumbnail: YÃ¼z, bÃ¼yÃ¼k metin, kontrast.
    6. Kategori: DoÄŸru kategori seÃ§in (EÄŸitim, EÄŸlence vs.)
    7. Dil ve altyazÄ±: Video dili doÄŸru seÃ§in; mÃ¼mkÃ¼nse otomatik altyazÄ±yÄ± dÃ¼zenleyin veya manuel altyazÄ± ekleyin.
    8. BÃ¶lÃ¼mler (chapters): AÃ§Ä±klamada timestamp ekleyin.
    9. Playlist: Ä°lgili bir oynatma listesine ekleyin.
    10. Pinned comment & End screen: Ä°lk yorumda CTAs, videonun sonunda end screen ekleyin.
    11. KÃ¼Ã§Ã¼k resim boyutu: 1280x720, JPG/PNG, max 2MB.
    12. YayÄ±n zamanÄ±: Hedef kitlenizin aktif olduÄŸu saatlerde yayÄ±nlayÄ±n (hafta iÃ§i akÅŸamlar vs).
    """)
    st.markdown("**Ä°leri Seviye Kanal BÃ¼yÃ¼tme Ä°puÃ§larÄ±:**")
    st.markdown("""
    - Ä°lk 10 saniye Ã¶nemlidir: hemen deÄŸeri gÃ¶sterin.
    - DÃ¼zenli iÃ§erik takvimi: haftada 1-2 video tavsiye edilir.
    - Ä°zleyici etkileÅŸimi: videonun sonunda aÃ§Ä±k bir CTA ile yorum/like/subscribe isteyin.
    - Thumbnail A/B testi: farklÄ± tasarÄ±mlar deneyin.
    - Analitik takibi: YouTube Studio'dan izlenme sÃ¼resi (watch time) ve click-through rate (CTR) takip edin.
    - KÄ±sa formatlarÄ± (Shorts) kullanarak kanal keÅŸfedilebilirliÄŸini artÄ±rÄ±n.
    """)
